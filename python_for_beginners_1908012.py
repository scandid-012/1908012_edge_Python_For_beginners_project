# -*- coding: utf-8 -*-
"""Python_For_Beginners_1908012.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zDHY4SkUSF2rJAq6616FMy0pZS1WZie

#load requred libraries
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import plotly.express as px
import plotly.io as pio

from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA

import warnings
warnings.filterwarnings('ignore')

"""#load dataset"""

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Advanced Soybean Agricultural Dataset.csv')
df

"""#apply pca and XGboost"""

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Selecting only numerical columns for PCA and XGBoost
num_cols = df.select_dtypes(include=['float64']).columns
X = df[num_cols].drop(columns=['Seed Yield per Unit Area (SYUA)'])  # Features
y = df['Seed Yield per Unit Area (SYUA)']  # Target

# Standardizing the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Training XGBoost Regressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5)
xgb_reg.fit(X_train, y_train)

# Predictions
y_pred = xgb_reg.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Applying PCA
pca = PCA(n_components=2)  # Reduce to 2 components for visualization
X_pca = pca.fit_transform(X_scaled)

# Scatter plot of PCA results
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Crop Data')
plt.show()

# Explained variance ratio
print("Explained variance ratio:", pca.explained_variance_ratio_)

"""#PCA and XGBoost with train test and validation"""

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error
import numpy as np

# Selecting only numerical columns for PCA and XGBoost
num_cols = df.select_dtypes(include=['float64']).columns
X = df[num_cols].drop(columns=['Seed Yield per Unit Area (SYUA)'])  # Features
y = df['Seed Yield per Unit Area (SYUA)']  # Target

# Standardizing the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Training XGBoost Regressor with validation
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5)

# Performing cross-validation
cv_scores = cross_val_score(xgb_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
cv_mse = np.mean(-cv_scores)
print(f"Cross-validated MSE: {cv_mse}")

# Fitting the model
xgb_reg.fit(X_train, y_train)

# Predictions
y_pred = xgb_reg.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error on Test Set: {mse}")

# Applying PCA
pca = PCA(n_components=2)  # Reduce to 2 components for visualization
X_pca = pca.fit_transform(X_scaled)

# Scatter plot of PCA results
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Crop Data')
plt.show()

# Explained variance ratio
print("Explained variance ratio:", pca.explained_variance_ratio_)

"""#Random Forest and mean squred error"""

from sklearn.model_selection import train_test_split, cross_val_score

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error



# Selecting numerical columns
num_cols = df.select_dtypes(include=['float64']).columns
X = df[num_cols].drop(columns=['Seed Yield per Unit Area (SYUA)'])  # Features
y = df['Seed Yield per Unit Area (SYUA)']  # Target

# Standardizing the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Training Random Forest Regressor
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)

# Cross-validation
cv_scores = cross_val_score(rf_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
cv_mse = np.mean(-cv_scores)
print(f"Cross-validated MSE: {cv_mse}")

# Fitting the model
rf_reg.fit(X_train, y_train)

# Predictions
y_pred = rf_reg.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error on Test Set: {mse}")